{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Web Scraping with Python - Starter Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFqstK5Hegki"
      },
      "source": [
        "# **Step 1: Loading modules**\n",
        "Before we start scrapping the target website, we need to import some necessary modules from the system library.\n",
        "*   “requests” includes the modules for sending HTTP requests to websites, the core step for web scrapping.\n",
        "*   “bs4/BeautifulSoup” includes the required APIs for cleaning and formatting the data collected from the web scrapper.\n",
        "*   “pandas” includes some essential functionalities for data analytics, allowing users to quickly manipulate and analyse them.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeSCpDTmtesQ"
      },
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z2wLcWuhPuk"
      },
      "source": [
        "# **Step 2: Naïve Scrapping Method (Scrapping Whole Page)**\n",
        "We will now introduce the simplest way to scrape the data from a website.\n",
        "*   Define a Python \"list\" for every column you identified in the stock price table from Yahoo! Finance.\n",
        "*   Add the URL of the target website in the code.\n",
        "*   Observe the stock price table and identify the column data that will be useful. Then, use the \"Inspect\" feature from Chrome to show the HTML content.\n",
        "*   Use for-loop to format the data collected from BeautifulSoup.\n",
        "\n",
        "\n",
        "**Discussions**\n",
        "1.   Try to discuss the advantages and disadvantages of the method above。\n",
        "2.   If the column name of the underlying table in the website changes, does this method still work?\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctr9TYQqjuCw"
      },
      "source": [
        "# TODO: Use requests and BeautifulSoup（BS）to scrape website data\n",
        "active_stocks_url = \"https://finance.yahoo.com/most-active\"\n",
        "\n",
        "# TODO: Define python lists for every column and get the HTML table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyaSOPqboO3T"
      },
      "source": [
        "\"\"\"\n",
        "Using the concepts of for-loop, find all the <tr> tags from \"stockTable\".\n",
        "Every <tr> tag represent a row of stock data (saved as listing).\n",
        "We need to find all the <td> tag from the \"listing\", and extract its info to be inserted to the relevant python list.\n",
        "\"\"\"\n",
        "# TODO: Fill in the relevant HTML tag in the find_all \"brackets\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shCJ3NnQjrhy"
      },
      "source": [
        "\"\"\"\n",
        "Use pandas to create a new data frame, aggregate all python lists into a single table.\n",
        "You will need to know how to use Python dictionary in this part.\n",
        "\"\"\"\n",
        "# TODO: Display the table using a Python dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grRwS5kB7jKc"
      },
      "source": [
        "# **Step 3: Naïve Scrapping Method (Scrapping Individual Rows)**\n",
        "*   Copy and paste the Yahoo Finance link for currencies。\n",
        "*   Use Chrome Inspector to inspect the HTML elements。\n",
        "\n",
        "**Discussions**\n",
        "1.   What is the difference of this method in terms of execution efficiency when compared to the previous method?\n",
        "2.   If the row header, does this method still works?\n",
        "3.   When should we use whole page scraping, when should we use individual row scraping?\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV6yyQhbtfn1"
      },
      "source": [
        "# TODO: Scrape website data and extract info into relevant Python lists\n",
        "currencies_url = \"https://finance.yahoo.com/currencies\"\n",
        "\n",
        "# TODO: Find the starting and ending data-reactid，and the difference between each column\n",
        "\n",
        "# TODO: Display the table using a Python dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzn5ZEhd_5fu"
      },
      "source": [
        "# **Step 4: Header Scraping Method**\n",
        "This method is an advanced scraping method. The code will automatically scrape the header so that we don't have to define the list for ourselves, making the code much simpler and cleaner.\n",
        "\n",
        "*   Copy and paste the Yahoo Finance link of cryptocurrencies\n",
        "*   Scrape the headers and put those into a python list\n",
        "*   Put the relevant data into a Python dictionary\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3HU2ghYvKBl"
      },
      "source": [
        "crypto_url = \"https://finance.yahoo.com/cryptocurrencies\"\n",
        "r = requests.get(crypto_url)\n",
        "data = r.text\n",
        "soup = BeautifulSoup(data)\n",
        "\n",
        "# TODO: Use a Python list and Python dictionaruy to scrape all the headers\n",
        "\n",
        "# TODO: Display the table using a Python dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eWlS2Gm_6RI"
      },
      "source": [
        "# **Step 5: Making a generic scraping function**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We are going to turn the header method into a Python function. This function can also work for other types of financial products!\n",
        "\n",
        "*   Define a good name for the function\n",
        "*   Define input paramters and input value\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9JOzNQBvOAl"
      },
      "source": [
        "# TODO: code a generic function scrape_table "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI2oNQv2_7ya"
      },
      "source": [
        "# **Concept Challenge: Scrape other products**\n",
        "Try using the generic function to scrape other products in Yahoo Finance!\n",
        "*   Gainers\n",
        "*   Losers\n",
        "*   Top ETFs\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNvxyl5j94H7"
      },
      "source": [
        "# TODO: Try using the generic function to scrape other kind of products (e.g. cryptocurrencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKAKj2xJVK6V"
      },
      "source": [
        "# Step 6: Data Wrangling \n",
        "\n",
        "**Datatype Conversion**\n",
        "\n",
        "This part will make use of the stock data we have collected from our web scrapper. However, the data collected are all stored as \"strings\". In other words, the data is regarded as textual data even if the underlying data is representing a number. We need to convert them into right formats for the chart plotting tools.\n",
        "\n",
        "Steps in data conversion：\n",
        "1.   Remove all the commas in the number data, and change columns that contain number data to floating point.\n",
        "2.   Change all columns that contain dates to datetime.\n",
        "3.   Recover abbreaviated numbers, for example, recover \"1M\" to 1000000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsggD1xaVUD1"
      },
      "source": [
        "from datetime import datetime\n",
        "def convert_column_to_float(df, columns):\n",
        "# TODO: code the logic for string to float\n",
        "\n",
        "def convert_column_to_datetime(df, columns):\n",
        "# TODO: code the logic for string to datetime\n",
        "\n",
        "def revert_scaled_number(number):\n",
        "# TODO: code the logic for converting the string apreviations back to numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfU571qkVWFD"
      },
      "source": [
        "**Filtering dataframe**\n",
        "\n",
        "- We can scrape all the active stocks easily now\n",
        "- Let's try to separate them into rising and losing stocks?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ6Y0KkXVVmC"
      },
      "source": [
        "# TODO: first scrape the active stocks table using the web scraper function\n",
        "\n",
        "# TODO: change the data type of the dataframe columns\n",
        "\n",
        "# TODO: filter the dataframe by % Change (pos/neg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eco574-_VaJ2"
      },
      "source": [
        "**Sorting dataframe**\n",
        "\n",
        "- It's not quite clear which stock is the top gainer/loser\n",
        "- We can sort the dataframe and see it clearly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3c09t5ZVbYG"
      },
      "source": [
        "rising = rising.sort_values(by=['% Change'], ascending=False)\n",
        "# TODO: get the losing stocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sTx9BUrVc6A"
      },
      "source": [
        "Finally, if you prefer, you can add back the \"+/-\" sign and the percentage symbol and convert back the value to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smQDnVEiVgyl"
      },
      "source": [
        "rising['% Change']='+' + rising['% Change'].astype(str) + '%'\n",
        "losing['% Change']=losing['% Change'].astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_JeMiINVhLF"
      },
      "source": [
        "rising"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}